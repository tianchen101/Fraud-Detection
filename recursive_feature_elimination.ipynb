{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "import lightgbm as lgb\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import multiprocessing\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 542.35 Mb (69.4% reduction)\n",
      "Mem. usage decreased to 472.59 Mb (68.9% reduction)\n",
      "Mem. usage decreased to 25.86 Mb (42.7% reduction)\n",
      "Mem. usage decreased to 25.44 Mb (42.7% reduction)\n"
     ]
    }
   ],
   "source": [
    "train_transaction = pd.read_csv('train_transaction.csv')\n",
    "test_transaction = pd.read_csv('test_transaction.csv')\n",
    "train_identity = pd.read_csv('train_identity.csv')\n",
    "test_identity = pd.read_csv('test_identity.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "# HERE DO THE MEMORY REDUCTION OPERATION\n",
    "train_transaction = reduce_mem_usage(train_transaction)\n",
    "test_transaction = reduce_mem_usage(test_transaction)\n",
    "train_identity = reduce_mem_usage(train_identity)\n",
    "test_identity = reduce_mem_usage(test_identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')\n",
    "test = pd.merge(test_transaction,test_identity,on='TransactionID',how='left')\n",
    "del train_transaction,test_transaction,train_identity,test_identity\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete Columns such that: <br>\n",
    "(1) a column null value > 90% of entries <br>\n",
    "(2) a column with only unique value <br>\n",
    "(3) a column with top feature appeared 90% of the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 features are going to be dropped for being useless\n"
     ]
    }
   ],
   "source": [
    "one_value_cols = [col for col in train.columns if train[col].nunique()<=1]\n",
    "one_value_cols_test = [col for col in test.columns if test[col].nunique() <=1]\n",
    "\n",
    "many_null_cols = [col for col in train.columns if train[col].isnull().sum()/ train.shape[0]>0.9]\n",
    "many_null_cols_test = [col for col in test.columns if test[col].isnull().sum() / test.shape[0] \\\n",
    "                       > 0.9]\n",
    "big_top_value_cols = [col for col in train.columns if train[col].value_counts( \\\n",
    "                                                dropna=False,normalize= True).values[0] >0.9]\n",
    "big_top_value_cols_test = [col for col in test.columns if test[col].value_counts( \\\n",
    "                                                dropna=False,normalize=True).values[0] > 0.9]\n",
    "cols_to_drop = list(set(one_value_cols + one_value_cols_test + many_null_cols \\\n",
    "                        + many_null_cols_test + big_top_value_cols + big_top_value_cols_test))\n",
    "try:\n",
    "    cols_to_drop.remove('isFraud')\n",
    "    print(\"{} features are going to be dropped for being useless\".format(len(cols_to_drop)))\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    train = train.drop(cols_to_drop,axis =1)\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    test = test.drop(cols_to_drop,axis =1)\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32df3cfd8c9943019ffb12d74f47e293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=352), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for col in tqdm_notebook(train.columns): \n",
    "    if train[col].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        le.fit(list(train[col].astype(str).values) + list(test[col].astype(str).values))\n",
    "        train[col] = le.transform(list(train[col].astype(str).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 426.33 Mb (73.2% reduction)\n"
     ]
    }
   ],
   "source": [
    "train = reduce_mem_usage(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TransactionID', 'isFraud', 'TransactionDT', 'TransactionAmt',\n",
       "       'ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5',\n",
       "       ...\n",
       "       'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38',\n",
       "       'DeviceType', 'DeviceInfo'],\n",
       "      dtype='object', length=352)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train.sort_values('TransactionDT').drop(['isFraud', 'TransactionDT', 'TransactionID'], axis=1)\n",
    "y = train.sort_values('TransactionDT')['isFraud']\n",
    "\n",
    "del train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFECV does not support NaNs\n",
    "X.fillna(-999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves': 491,\n",
    "          'min_child_weight': 0.03454472573214212,\n",
    "          'feature_fraction': 0.3797454081646243,\n",
    "          'bagging_fraction': 0.4181193142567742,\n",
    "          'min_data_in_leaf': 106,\n",
    "          'objective': 'binary',\n",
    "          'max_depth': -1,\n",
    "          'learning_rate': 0.006883242363721497,\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"bagging_seed\": 11,\n",
    "          \"metric\": 'auc',\n",
    "          \"verbosity\": -1,\n",
    "          'reg_alpha': 0.3899927210061127,\n",
    "          'reg_lambda': 0.6485237330340494,\n",
    "          'random_state': 47\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = lgb.LGBMClassifier(**params)\n",
    "rfe = RFECV(estimator=clf, step=10, cv=KFold(n_splits=5, \\\n",
    "            shuffle=False), scoring='roc_auc', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 349 features.\n",
      "Fitting estimator with 339 features.\n",
      "Fitting estimator with 329 features.\n",
      "Fitting estimator with 319 features.\n",
      "Fitting estimator with 309 features.\n",
      "Fitting estimator with 299 features.\n",
      "Fitting estimator with 289 features.\n",
      "Fitting estimator with 279 features.\n",
      "Fitting estimator with 269 features.\n",
      "Fitting estimator with 259 features.\n",
      "Fitting estimator with 249 features.\n",
      "Fitting estimator with 239 features.\n",
      "Fitting estimator with 229 features.\n",
      "Fitting estimator with 219 features.\n",
      "Fitting estimator with 209 features.\n",
      "Fitting estimator with 199 features.\n",
      "Fitting estimator with 189 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 169 features.\n",
      "Fitting estimator with 159 features.\n",
      "Fitting estimator with 149 features.\n",
      "Fitting estimator with 139 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 119 features.\n",
      "Fitting estimator with 109 features.\n",
      "Fitting estimator with 99 features.\n",
      "Fitting estimator with 89 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 349 features.\n",
      "Fitting estimator with 339 features.\n",
      "Fitting estimator with 329 features.\n",
      "Fitting estimator with 319 features.\n",
      "Fitting estimator with 309 features.\n",
      "Fitting estimator with 299 features.\n",
      "Fitting estimator with 289 features.\n",
      "Fitting estimator with 279 features.\n",
      "Fitting estimator with 269 features.\n",
      "Fitting estimator with 259 features.\n",
      "Fitting estimator with 249 features.\n",
      "Fitting estimator with 239 features.\n",
      "Fitting estimator with 229 features.\n",
      "Fitting estimator with 219 features.\n",
      "Fitting estimator with 209 features.\n",
      "Fitting estimator with 199 features.\n",
      "Fitting estimator with 189 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 169 features.\n",
      "Fitting estimator with 159 features.\n",
      "Fitting estimator with 149 features.\n",
      "Fitting estimator with 139 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 119 features.\n",
      "Fitting estimator with 109 features.\n",
      "Fitting estimator with 99 features.\n",
      "Fitting estimator with 89 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 349 features.\n",
      "Fitting estimator with 339 features.\n",
      "Fitting estimator with 329 features.\n",
      "Fitting estimator with 319 features.\n",
      "Fitting estimator with 309 features.\n",
      "Fitting estimator with 299 features.\n",
      "Fitting estimator with 289 features.\n",
      "Fitting estimator with 279 features.\n",
      "Fitting estimator with 269 features.\n",
      "Fitting estimator with 259 features.\n",
      "Fitting estimator with 249 features.\n",
      "Fitting estimator with 239 features.\n",
      "Fitting estimator with 229 features.\n",
      "Fitting estimator with 219 features.\n",
      "Fitting estimator with 209 features.\n",
      "Fitting estimator with 199 features.\n",
      "Fitting estimator with 189 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 169 features.\n",
      "Fitting estimator with 159 features.\n",
      "Fitting estimator with 149 features.\n",
      "Fitting estimator with 139 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 119 features.\n",
      "Fitting estimator with 109 features.\n",
      "Fitting estimator with 99 features.\n",
      "Fitting estimator with 89 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 349 features.\n",
      "Fitting estimator with 339 features.\n",
      "Fitting estimator with 329 features.\n",
      "Fitting estimator with 319 features.\n",
      "Fitting estimator with 309 features.\n",
      "Fitting estimator with 299 features.\n",
      "Fitting estimator with 289 features.\n",
      "Fitting estimator with 279 features.\n",
      "Fitting estimator with 269 features.\n",
      "Fitting estimator with 259 features.\n",
      "Fitting estimator with 249 features.\n",
      "Fitting estimator with 239 features.\n",
      "Fitting estimator with 229 features.\n",
      "Fitting estimator with 219 features.\n",
      "Fitting estimator with 209 features.\n",
      "Fitting estimator with 199 features.\n",
      "Fitting estimator with 189 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 169 features.\n",
      "Fitting estimator with 159 features.\n",
      "Fitting estimator with 149 features.\n",
      "Fitting estimator with 139 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 119 features.\n",
      "Fitting estimator with 109 features.\n",
      "Fitting estimator with 99 features.\n",
      "Fitting estimator with 89 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 349 features.\n",
      "Fitting estimator with 339 features.\n",
      "Fitting estimator with 329 features.\n",
      "Fitting estimator with 319 features.\n",
      "Fitting estimator with 309 features.\n",
      "Fitting estimator with 299 features.\n",
      "Fitting estimator with 289 features.\n",
      "Fitting estimator with 279 features.\n",
      "Fitting estimator with 269 features.\n",
      "Fitting estimator with 259 features.\n",
      "Fitting estimator with 249 features.\n",
      "Fitting estimator with 239 features.\n",
      "Fitting estimator with 229 features.\n",
      "Fitting estimator with 219 features.\n",
      "Fitting estimator with 209 features.\n",
      "Fitting estimator with 199 features.\n",
      "Fitting estimator with 189 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 169 features.\n",
      "Fitting estimator with 159 features.\n",
      "Fitting estimator with 149 features.\n",
      "Fitting estimator with 139 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 119 features.\n",
      "Fitting estimator with 109 features.\n",
      "Fitting estimator with 99 features.\n",
      "Fitting estimator with 89 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 9 features.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RFECV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "   estimator=LGBMClassifier(bagging_fraction=0.4181193142567742, bagging_seed=11,\n",
       "        boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        feature_fraction=0.3797454081646243, importance_type='split',\n",
       "        learning_rate=0.006883242363721497, max_depth=-1, metric='auc',\n",
       "        ...       silent=True, subsample=1.0, subsample_for_bin=200000,\n",
       "        subsample_freq=0, verbosity=-1),\n",
       "   n_jobs=1, scoring='roc_auc', step=10, verbose=2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransactionAmt\n",
      "ProductCD\n",
      "card1\n",
      "card2\n",
      "card3\n",
      "card4\n",
      "card5\n",
      "card6\n",
      "addr1\n",
      "dist1\n",
      "P_emaildomain\n",
      "R_emaildomain\n",
      "C1\n",
      "C2\n",
      "C4\n",
      "C5\n",
      "C6\n",
      "C7\n",
      "C8\n",
      "C9\n",
      "C10\n",
      "C11\n",
      "C12\n",
      "C13\n",
      "C14\n",
      "D1\n",
      "D2\n",
      "D3\n",
      "D4\n",
      "D5\n",
      "D6\n",
      "D8\n",
      "D9\n",
      "D10\n",
      "D11\n",
      "D12\n",
      "D13\n",
      "D14\n",
      "D15\n",
      "M2\n",
      "M3\n",
      "M4\n",
      "M5\n",
      "M6\n",
      "M8\n",
      "M9\n",
      "V4\n",
      "V5\n",
      "V12\n",
      "V13\n",
      "V19\n",
      "V20\n",
      "V30\n",
      "V34\n",
      "V35\n",
      "V36\n",
      "V37\n",
      "V38\n",
      "V44\n",
      "V45\n",
      "V47\n",
      "V53\n",
      "V54\n",
      "V56\n",
      "V57\n",
      "V58\n",
      "V61\n",
      "V62\n",
      "V70\n",
      "V74\n",
      "V75\n",
      "V76\n",
      "V78\n",
      "V82\n",
      "V83\n",
      "V87\n",
      "V91\n",
      "V94\n",
      "V96\n",
      "V97\n",
      "V99\n",
      "V126\n",
      "V127\n",
      "V128\n",
      "V130\n",
      "V131\n",
      "V139\n",
      "V143\n",
      "V149\n",
      "V152\n",
      "V160\n",
      "V165\n",
      "V170\n",
      "V187\n",
      "V189\n",
      "V201\n",
      "V203\n",
      "V204\n",
      "V207\n",
      "V208\n",
      "V209\n",
      "V210\n",
      "V212\n",
      "V217\n",
      "V221\n",
      "V222\n",
      "V234\n",
      "V257\n",
      "V258\n",
      "V261\n",
      "V264\n",
      "V265\n",
      "V266\n",
      "V267\n",
      "V268\n",
      "V271\n",
      "V274\n",
      "V275\n",
      "V277\n",
      "V278\n",
      "V279\n",
      "V280\n",
      "V282\n",
      "V283\n",
      "V285\n",
      "V287\n",
      "V289\n",
      "V291\n",
      "V292\n",
      "V294\n",
      "V306\n",
      "V307\n",
      "V308\n",
      "V310\n",
      "V312\n",
      "V313\n",
      "V314\n",
      "V315\n",
      "V317\n",
      "V323\n",
      "V324\n",
      "V332\n",
      "V333\n",
      "id_01\n",
      "id_02\n",
      "id_05\n",
      "id_06\n",
      "id_09\n",
      "id_13\n",
      "id_14\n",
      "id_17\n",
      "id_19\n",
      "id_20\n",
      "id_30\n",
      "id_31\n",
      "id_33\n",
      "id_38\n",
      "DeviceType\n",
      "DeviceInfo\n"
     ]
    }
   ],
   "source": [
    "for col in X.columns[rfe.ranking_ ==1 ]:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ProductCD'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>card6</th>\n",
       "      <th>addr1</th>\n",
       "      <th>addr2</th>\n",
       "      <th>...</th>\n",
       "      <th>id_31</th>\n",
       "      <th>id_32</th>\n",
       "      <th>id_33</th>\n",
       "      <th>id_34</th>\n",
       "      <th>id_35</th>\n",
       "      <th>id_36</th>\n",
       "      <th>id_37</th>\n",
       "      <th>id_38</th>\n",
       "      <th>DeviceType</th>\n",
       "      <th>DeviceInfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68.5</td>\n",
       "      <td>4</td>\n",
       "      <td>13926</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1</td>\n",
       "      <td>142.0</td>\n",
       "      <td>1</td>\n",
       "      <td>315.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>136</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>461</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2755</td>\n",
       "      <td>404.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1</td>\n",
       "      <td>325.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>136</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>461</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4663</td>\n",
       "      <td>490.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>4</td>\n",
       "      <td>166.0</td>\n",
       "      <td>2</td>\n",
       "      <td>330.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>136</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>461</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>4</td>\n",
       "      <td>18132</td>\n",
       "      <td>567.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2</td>\n",
       "      <td>117.0</td>\n",
       "      <td>2</td>\n",
       "      <td>476.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>136</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>461</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4497</td>\n",
       "      <td>514.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1</td>\n",
       "      <td>420.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>162</td>\n",
       "      <td>32.0</td>\n",
       "      <td>268</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 349 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionAmt  ProductCD  card1  card2  card3  card4  card5  card6  addr1  \\\n",
       "0            68.5          4  13926 -999.0  150.0      1  142.0      1  315.0   \n",
       "1            29.0          4   2755  404.0  150.0      2  102.0      1  325.0   \n",
       "2            59.0          4   4663  490.0  150.0      4  166.0      2  330.0   \n",
       "3            50.0          4  18132  567.0  150.0      2  117.0      2  476.0   \n",
       "4            50.0          1   4497  514.0  150.0      2  102.0      1  420.0   \n",
       "\n",
       "   addr2     ...      id_31  id_32  id_33  id_34  id_35  id_36  id_37  id_38  \\\n",
       "0   87.0     ...        136 -999.0    461      4      2      2      2      2   \n",
       "1   87.0     ...        136 -999.0    461      4      2      2      2      2   \n",
       "2   87.0     ...        136 -999.0    461      4      2      2      2      2   \n",
       "3   87.0     ...        136 -999.0    461      4      2      2      2      2   \n",
       "4   87.0     ...        162   32.0    268      3      1      0      1      1   \n",
       "\n",
       "   DeviceType  DeviceInfo  \n",
       "0           2        2740  \n",
       "1           2        2740  \n",
       "2           2        2740  \n",
       "3           2        2740  \n",
       "4           1        1565  \n",
       "\n",
       "[5 rows x 349 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pickle to save the selected features\n",
    "import pickle\n",
    "selected_features = [col for col in X.columns[rfe.ranking_ ==1] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('slected_features.pkl','wb') as f:\n",
    "    pickle.dump(selected_features,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
